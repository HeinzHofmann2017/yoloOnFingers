\newpage
\section{Resultate}
\label{chapter:resultate}
\subsection{Testvoraussetzungen}
Das Netzwerk wurde auf 1'200'000 Bildern des ImageNet-1000-class-Datasets vortrainiert.
Danach wurde es auf rund 13'900 Bildern aus dem Testaufbau \cite{TabeasFingertracking} trainiert. 
Der Test wiederum wurde auf rund 1'500 Bildern ebenfalls aus dem Testaufbau \cite{TabeasFingertracking} getestet. 
Diese Testbilder waren dem Algorithmus während des Lernprozesses nicht zugänglich und haben entsprechend keinen Einfluss auf den Lernprozess genommen. 
Ausserdem wurden diese Bilder so gewählt, dass sie nicht gleichzeitig mit den Trainingsbildern aufgenommen wurden. 
Dies verhinderte, dass fast identische Bilder im Training und im Test vorkommen. 

\subsection{Analyse}
Um die Genauigkeit der Predictions unseres Neuronalen Netzwerkes möglichst exakt beschreiben zu können, wurden die zwei Werte Distanz und IOU gewählt (siehe Kapitel \ref{chapter:letztendlicher_test}). 
Obwohl die beiden Werte korrelieren, sagt jeder für sich nicht die volle Wahrheit über die Genauigkeit der Vorhersagen aus. 
Die Distanz ist für die geplante Anwendung der wesentlichere Wert, weil sie Informationen über den Standort der Fingerspitze im Bild preisgibt.
Die IOU ist mit der Distanz teilweise korreliert, da die IOU neben der Distanz auch von der Grösse der Boundingboxen abhängt.
Sobald die Boundingbox der Prediction und die Boundingbox des Labels sich zu überlappen beginnen, sagt die IOU etwas über die korrekte Vorhersage von Breite und Höhe der Boundingbox aus.

\subsubsection{Distanz}

%Einschätzung der Distanz:
\begin{figure}	
	\centering
	\includegraphics[width=.7\textwidth]{Kapitel/70Resultate/Bilder/DistanzenBerechnung.pdf}
	\caption{Bedeutung der normierten Distanzwerte in der realen Welt}
	\label{img:explain_normed_distance}
\end{figure}

%Beispielbilder Distanz
\begin{figure}
	\centering
	\begin{minipage}[b]{0.48\textwidth}	
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/2distKnappGut.png}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.48\textwidth}		
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/5distKnappGut.png}
	\end{minipage}
	\caption{Prediction knapp besser als Distanz=0.02}
	\label{img:distanz_knapp_gut}
	%Eine Leerzeile einfügen	
	\begin{verbatim}
	\end{verbatim}
	\centering
	\begin{minipage}[b]{0.48\textwidth}	
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/3distKnappSchlecht.png}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.48\textwidth}		
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/4distKnappSchlecht.png}
	\end{minipage}
	\caption{Prediction knapp schlechter als Distanz=0.02}	
	\label{img:distanz_knapp_schlecht}
\end{figure}

%Komplette Wahrscheinlichkeits-Dichte-Funktion der Distanz
\begin{figure}	
	\centering
	\includegraphics[width=.7\textwidth]{Kapitel/70Resultate/Bilder/distProbDensity.pdf}
	\caption{Komplette Wahrscheinlichkeits-Dichte-Funktion der Distanz (Grenze: Dist=0.02)}
	\label{img:dist_dichte}
\end{figure}
%Komplette Wahrscheinlichkeits-Dichte-Funktion mit Logarithmischer y-Achse
\begin{figure}	
	\centering
	\includegraphics[width=.7\textwidth]{Kapitel/70Resultate/Bilder/logdistProbDensity.pdf}
	\caption{Komplette Wahrscheinlichkeits-Dichte-Funktion der Distanz mit Logarithmischer y-Achse (Grenze: Dist=0.02)}
	\label{img:log_dist_dichte}
\end{figure}
%Wahrscheinlichkeits-Dichtefunktion der Distanz. Ausreisser nicht miteingerechnet
\begin{figure}	
	\centering
	\includegraphics[width=.7\textwidth]{Kapitel/70Resultate/Bilder/distProbDensity_improved.pdf}
	\caption{Wahrscheinlichkeits-Dichtefunktion der Distanz. Ausreisser nicht miteingerechnet (Grenze: Dist=0.02)}
	\label{img:dist_dichte_improved}
\end{figure}

Die Distanz beschreibt die normierte Differenz zwischen dem Zentrumspunkt des Labels und dem Zentrumspunkt der Vorhersage. 
Sämtliche Distanzen wurden so normiert, dass die Höhe des Bildes und auch die Breite gleich eins sind. 
Die maximale Distanz zwischen zwei Punkten ist also die Diagonale über ein Bild, welche entsprechend sqrt(2) ist.
Was diese Normierten Distanzen in der realen Welt bedeuten ist auf Abbildung \ref{img:explain_normed_distance} erklärt. 
Zum Vergleich, ein menschlicher Zeigefinger ist zwischen 10 und 20 mm breit.
Eine normierte Distanz von 0.02 entspricht auf unserem Versuchsaufbau somit ziemlich genau der Breite eines menschlichen Fingers. 

Um die Resultate in gut und schlecht einteilen zu können wurde ein Threshold von 0.02 definiert.
Die Definition dieses Thresholds wurde gemacht, indem Bilder zusammen mit der entsprechenden Distanz analysiert wurden.
Der Wert 0.02 entspricht somit derjenigen Distanz, welche gerade noch knapp annehmbar ist, um einen Finger als detektiert gelten zu lassen.
Um ein Gefühl für diese Distanzen zu bekommen, lohnt es sich die Abbildungen \ref{img:distanz_knapp_gut} \& \ref{img:distanz_knapp_schlecht} anzusehen, welche Bilder zeigen, die eine Distanz nahe dieses Thresholds aufweisen. 

Um die Verteilung der Distanzen gut verstehen zu können, ist in Abbildung \ref{img:dist_dichte} eine Wahrscheinlichkeitsdichte der Distanzen im Testset zu sehen. Diese Dichtefunktion wurde erst nach der Bestimmung des Thresholds erzeugt und zeigt, dass rund 84\% der Distanzen kürzer sind als 0.02 und somit die entsprechenden Finger \grqq{}erfolgreich\grqq{} erkannt wurden.

Erstaunlich ist auch, dass die Distanzen, welche grösser als 0.25 sind in der Wahrscheinlichkeitsdichte in kleinen Bündeln vorkommen. 
Dies lässt darauf schliessen, dass die Trainingsdaten nicht komplett Bias-Frei sind.
Erstaunlich ist auch, dass es um die Distanz von 0.4 die Wahrscheinlichkeitsdichte als eine Art Bündel auftritt.
Dies ist in der Abbildung \ref{img:log_dist_dichte}, welche eine logarithmisches Abbild von Abbildung \ref{img:dist_dichte} ist, gut zu sehen.
Nach kurzer Kontrolle konnte tatsächlich festgestellt werden, dass z.B. bei einer Distanz von ca. 0.4 immer ein bestimmter Punkt des Hintergrundes vorhergesagt wurde, welcher sehr selten in den Labels als Finger markiert wurde. 

Die Statistik sollte nicht von Ausreissern, welche aufgrund von falschen Labels entstanden sind,verfälscht werden.
Deshalb wurde wie in Abbildung \ref{img:dist_dichte_improved} noch eine zweite Wahrscheinlichkeitsdichte-Funktion erstellt. 
Dabei wurden alle Distanzen, welche grösser als 0.25 waren, gelöscht.

Wie man ausserdem aus Kapitel \ref{chapter:fingerdetektion} entnehmen kann, gab es schon in der Erzeugung der Labels eine gewisse Unschärfe.
So hat auf Abbildung \ref{img:Erosion}  der y-Wert im Vergleich vom einen Bild zum anderen und relativ zum Finger eine Differenz von rund 10 Pixeln, was im normierten Mass einer Distanz von rund 0.02 entspricht.
Um dieses Problem aufzeigen zu können wurde ein Bild mit einem klaren Unterschied verwendet, was bedeutet dass die meisten Labels Fehler haben, die kleiner als diese Grenze sind.
Nichtsdestotrotz wird man wohl nie in der Lage sein, viel bessere Resultate in der Genauigkeit einzufahren, wenn die Labels noch solche Abweichungen aufweisen.

Es kann sehr gut sein, dass in der Arbeit \grqq{}Hand Pose Estimation\grqq{} \cite{HandPoseEstimation} bessere Labels erzeugt wurden.
Denn in dieser Arbeit\cite{HandPoseEstimation} wurden die Fingerspitzen im 3D-Raum bestimmt und anschliessend in den 2D-Raum zurückgemappt.
Ausserdem wurde eine Fehlerrechnung gemacht, wie weit die 2D-Labels mit den zurückprojezierten Labels aus dem 3D-Raum übereinstimmen. 
Allerdings wurde in der erwähnten Arbeit\cite{HandPoseEstimation} kein Vergleich gemacht wie dies in dieser Arbeit der Fall ist.
Deshalb kann keine abschliessende Aussage zu diesem Thema gemacht werden.

\subsubsection{Intersection Over Union IOU}
%Beispielbilder IOU
\begin{figure}
	\centering
	\begin{minipage}[b]{0.48\textwidth}	
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/7iouKnappGut.png}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.48\textwidth}		
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/8iouKnappGut.png}
	\end{minipage}
	\caption{Prediction knapp besser als IOU=0.4}
	\label{img:iou_knapp_gut}
	%Eine Leerzeile einfügen	
	\begin{verbatim}
	\end{verbatim}
	\centering
	\begin{minipage}[b]{0.48\textwidth}	
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/6iouKnappSchlecht.png}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.48\textwidth}		
		\includegraphics[width=\textwidth]{Kapitel/70Resultate/Bilder/9iouKnappSchlecht.png}
	\end{minipage}
	\caption{Prediction knapp schlechter als IOU=0.4}
	\label{img:iou_knapp_schlecht}
\end{figure}
%Wahrscheinlichkeits-Dichte-Funktion der IOU
\begin{figure}
	\centering
	\includegraphics[width=.7\textwidth]{Kapitel/70Resultate/Bilder/IOUprobDensity.pdf}
	\caption{Wahrscheinlichkeits-Dichte-Funktion der IOU (Grenze: IOU=0.4)}
	\label{img:iou_dichte}
\end{figure}


Die IOU beschreibt die Überlappung der vorhergesagten Boundingbox und der Boundingbox des Labels. 
Daher sagt die IOU etwas über die korrekte Grösse der Boundingbox, sowie deren korrekte Lage aus. 
Um wieder etwas über gut und schlecht aussagen zu können, wurde wieder ein Threshold definiert (0.4).
Da durch die IOU, wie erwähnt, mehrere Faktoren beschrieben werden, ist die Grenze verschwommener. 
So gibt es nach menschlicher Ansicht hervorragende Vorhersagen, welche eine IOU von 0.3 haben und wiederum mässige Vorhersagen mit einer IOU von nahezu 0.4.
Um ein Gefühl für diesen Threshold zu bekommen, lohnt es sich, die Abbildungen \ref{img:iou_knapp_gut} \& \ref{img:iou_knapp_schlecht} zu berücksichtigen.
So fiel die Entscheidung den Threshold konservativ zu wählen, sodass nur Werte als gut erachtet werden können, welche auch gut sind. 

Auch für die IOU gibt es zur Übersicht eine Wahrscheinlichkeitsdichte die in Abbildung \ref{img:iou_dichte} betrachtet werden kann.
Aus dieser Grafik kann gelesen werden, dass rund 6\% der Vorhersagen klar falsch sind, weil die IOU nur Null ist, wenn sich die beiden Boundingboxen nicht berühren. Entsprechend kann gesagt werden, dass rund 94\% der Vorhersagen zumindest sehr grob richtig sind, weil sich bei diesen 94\% die Boundingboxen von Label und Prediction zumindest ein ganz kleines bisschen überlappen. 

Genau wie bei der Distanz gibt es auch bei der IOU, bzw. bei den Boundingboxen eine gewisse Unschärfe in den Labels (siehe Kapitel \ref{chapter:fingerdetektion}).
So haben die beiden Bilder in Abbildung \ref{img:Erosion} wenn man Sie zueinander normiert gegenüber einander eine IOU von knapp $0.4$.
Wie bei den Labelfehlern in der Distanz dürften die Fehler auch bei den Boundingboxen klar kleiner als im hier berechneten Beispiel sein.
Nichtsdestotrotz wird man wohl auch hier nie in der Lage sein viel bessere Resultate in der Genauigkeit einzufahren, wenn die Labels noch solche Abweichungen aufweisen.

\subsection{Erkenntnis}
Dass die Fehler in Distanz und IOU nahezu genau auf die gesetzten Grenzen zur Bewertung der Resultate fielen, war reiner Zufall.
So sind die Grenzen gemacht worden, bevor IOU und Distanz der Labels dieser zwei Bilder (Abbildung \ref{img:Erosion}) zueinander berechnet wurden.

Diese Erkenntnis jedoch relativiert sämtliche Resultate, wie sie in diesem Kapitel beschrieben wurden.
Angenommen es könnten noch mit perfekten Labels gearbeitet werden, gibt es folgende Hypothesen, wie sich die Vorhersagen verhalten werden:
\begin{enumerate}
\item Die Vorhersagen werden ebenfalls besser, weil es sich bei den Fehlern in den Labels um einen Bias und nicht bloss um Varianz gehandelt hatte.
\item Die Vorhersagen bleiben gleich gut, weil es sich bei den Fehlern in den Labels um Varianz und nicht um einen Bias gehandelt hatte.
\end{enumerate}
Beide Hypothesen wären möglich, können aber leider erst überprüft werden, wenn \grqq{}perfekte\grqq{} Label-Daten zur Verfügung stehen. 



